{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47210983",
   "metadata": {},
   "source": [
    "### Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61350ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19, MobileNetV2, ResNet50\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg_preprocess\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299bb7d",
   "metadata": {},
   "source": [
    "### Set Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9320ea90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m3rd year\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m5th SEM Materials of SR.Mishra(3rd yr)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDeep Learning for Image Analytics\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGroundnut_Leaf_dataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMain Used Dataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mretail_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train_dir = r\"E:\\A\\OneDrive\\Documents\\3rd year\\5th SEM Materials of SR.Mishra(3rd yr)\\Deep Learning for Image Analytics\\Project\\Groundnut_Leaf_dataset\\Main Used Dataset\"\n",
    "\n",
    "# Updated image size\n",
    "img_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb1c666",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37a4536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6329 images belonging to 6 classes.\n",
      "Found 1581 images belonging to 6 classes.\n",
      "Number of classes: 6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data generator with normalization and validation split\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Training data generator\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,     # Changed to (224, 224)\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,     # Changed to (224, 224)\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Print number of classes\n",
    "num_classes = len(train_gen.class_indices)\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a61d207",
   "metadata": {},
   "source": [
    "### Helper Function for Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90358b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(base_model, preprocess_func):\n",
    "    base_model.trainable = False\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(224, 224, 3)),  # Updated from (128,128,3)\n",
    "        tf.keras.layers.Lambda(preprocess_func),\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(1e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aeeea1",
   "metadata": {},
   "source": [
    "### Train with ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ae8e03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 890ms/step - accuracy: 0.1898 - loss: 1.8038 - val_accuracy: 0.2650 - val_loss: 1.7669\n",
      "Epoch 2/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 782ms/step - accuracy: 0.2375 - loss: 1.7526 - val_accuracy: 0.2808 - val_loss: 1.7480\n",
      "Epoch 3/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 670ms/step - accuracy: 0.2842 - loss: 1.7250 - val_accuracy: 0.2815 - val_loss: 1.7321\n",
      "Epoch 4/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 675ms/step - accuracy: 0.3068 - loss: 1.6965 - val_accuracy: 0.3378 - val_loss: 1.7153\n",
      "Epoch 5/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.3291 - loss: 1.6754 - val_accuracy: 0.3017 - val_loss: 1.7019\n",
      "Epoch 6/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.3307 - loss: 1.6557 - val_accuracy: 0.3365 - val_loss: 1.6869\n",
      "Epoch 7/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 676ms/step - accuracy: 0.3505 - loss: 1.6336 - val_accuracy: 0.3080 - val_loss: 1.6747\n",
      "Epoch 8/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 670ms/step - accuracy: 0.3625 - loss: 1.6121 - val_accuracy: 0.3460 - val_loss: 1.6601\n",
      "Epoch 9/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 677ms/step - accuracy: 0.3659 - loss: 1.5930 - val_accuracy: 0.3409 - val_loss: 1.6477\n",
      "Epoch 10/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 671ms/step - accuracy: 0.3658 - loss: 1.5773 - val_accuracy: 0.3529 - val_loss: 1.6389\n",
      "Epoch 11/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 679ms/step - accuracy: 0.3689 - loss: 1.5613 - val_accuracy: 0.3536 - val_loss: 1.6307\n",
      "Epoch 12/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.3822 - loss: 1.5482 - val_accuracy: 0.3517 - val_loss: 1.6250\n",
      "Epoch 13/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.3839 - loss: 1.5306 - val_accuracy: 0.3561 - val_loss: 1.6148\n",
      "Epoch 14/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.3915 - loss: 1.5209 - val_accuracy: 0.3555 - val_loss: 1.6087\n",
      "Epoch 15/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 674ms/step - accuracy: 0.3904 - loss: 1.5085 - val_accuracy: 0.3643 - val_loss: 1.6013\n",
      "Epoch 16/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.3975 - loss: 1.4999 - val_accuracy: 0.3567 - val_loss: 1.6009\n",
      "Epoch 17/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 671ms/step - accuracy: 0.3999 - loss: 1.4929 - val_accuracy: 0.3567 - val_loss: 1.5913\n",
      "Epoch 18/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.3999 - loss: 1.4844 - val_accuracy: 0.3574 - val_loss: 1.5898\n",
      "Epoch 19/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 671ms/step - accuracy: 0.4026 - loss: 1.4753 - val_accuracy: 0.3612 - val_loss: 1.5862\n",
      "Epoch 20/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 671ms/step - accuracy: 0.4056 - loss: 1.4724 - val_accuracy: 0.3650 - val_loss: 1.5828\n",
      "Epoch 21/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.4095 - loss: 1.4607 - val_accuracy: 0.3491 - val_loss: 1.5891\n",
      "Epoch 22/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 675ms/step - accuracy: 0.4165 - loss: 1.4580 - val_accuracy: 0.3510 - val_loss: 1.5891\n",
      "Epoch 23/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 670ms/step - accuracy: 0.4201 - loss: 1.4519 - val_accuracy: 0.3599 - val_loss: 1.5684\n",
      "Epoch 24/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4159 - loss: 1.4455 - val_accuracy: 0.3650 - val_loss: 1.5791\n",
      "Epoch 25/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4124 - loss: 1.4402 - val_accuracy: 0.3694 - val_loss: 1.5634\n",
      "Epoch 26/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4233 - loss: 1.4312 - val_accuracy: 0.3618 - val_loss: 1.5689\n",
      "Epoch 27/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.4247 - loss: 1.4296 - val_accuracy: 0.3675 - val_loss: 1.5617\n",
      "Epoch 28/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4307 - loss: 1.4230 - val_accuracy: 0.3599 - val_loss: 1.5678\n",
      "Epoch 29/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 675ms/step - accuracy: 0.4260 - loss: 1.4205 - val_accuracy: 0.3643 - val_loss: 1.5595\n",
      "Epoch 30/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4309 - loss: 1.4176 - val_accuracy: 0.3656 - val_loss: 1.5578\n",
      "Epoch 31/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.4318 - loss: 1.4150 - val_accuracy: 0.3643 - val_loss: 1.5612\n",
      "Epoch 32/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 674ms/step - accuracy: 0.4351 - loss: 1.4110 - val_accuracy: 0.3688 - val_loss: 1.5603\n",
      "Epoch 33/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.4392 - loss: 1.4010 - val_accuracy: 0.3637 - val_loss: 1.5625\n",
      "Epoch 34/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4288 - loss: 1.3955 - val_accuracy: 0.3681 - val_loss: 1.5508\n",
      "Epoch 35/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.4366 - loss: 1.3915 - val_accuracy: 0.3624 - val_loss: 1.5582\n",
      "Epoch 36/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 677ms/step - accuracy: 0.4350 - loss: 1.3875 - val_accuracy: 0.3669 - val_loss: 1.5463\n",
      "Epoch 37/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.4476 - loss: 1.3947 - val_accuracy: 0.3713 - val_loss: 1.5429\n",
      "Epoch 38/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4418 - loss: 1.3824 - val_accuracy: 0.3776 - val_loss: 1.5526\n",
      "Epoch 39/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4424 - loss: 1.3798 - val_accuracy: 0.3707 - val_loss: 1.5457\n",
      "Epoch 40/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 672ms/step - accuracy: 0.4535 - loss: 1.3749 - val_accuracy: 0.3763 - val_loss: 1.5414\n",
      "Epoch 41/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4405 - loss: 1.3762 - val_accuracy: 0.3744 - val_loss: 1.5394\n",
      "Epoch 42/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 675ms/step - accuracy: 0.4514 - loss: 1.3665 - val_accuracy: 0.3782 - val_loss: 1.5342\n",
      "Epoch 43/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 675ms/step - accuracy: 0.4457 - loss: 1.3733 - val_accuracy: 0.3763 - val_loss: 1.5301\n",
      "Epoch 44/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 675ms/step - accuracy: 0.4530 - loss: 1.3668 - val_accuracy: 0.3738 - val_loss: 1.5318\n",
      "Epoch 45/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4525 - loss: 1.3563 - val_accuracy: 0.3776 - val_loss: 1.5301\n",
      "Epoch 46/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4513 - loss: 1.3596 - val_accuracy: 0.3839 - val_loss: 1.5265\n",
      "Epoch 47/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4577 - loss: 1.3555 - val_accuracy: 0.3801 - val_loss: 1.5330\n",
      "Epoch 48/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 673ms/step - accuracy: 0.4494 - loss: 1.3511 - val_accuracy: 0.3858 - val_loss: 1.5256\n",
      "Epoch 49/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 676ms/step - accuracy: 0.4520 - loss: 1.3523 - val_accuracy: 0.3839 - val_loss: 1.5314\n",
      "Epoch 50/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 670ms/step - accuracy: 0.4631 - loss: 1.3485 - val_accuracy: 0.3751 - val_loss: 1.5397\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping callback\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',       # monitor validation loss\n",
    "    patience=5,               # stop if no improvement for 5 epochs\n",
    "    restore_best_weights=True # keep best model weights\n",
    ")\n",
    "\n",
    "# Build ResNet50 base model\n",
    "resnet_base = ResNet50(\n",
    "    weights=\"imagenet\",       # use pretrained ImageNet weights\n",
    "    include_top=False,        # exclude the fully connected layer\n",
    "    input_shape=(128, 128, 3)\n",
    ")\n",
    "\n",
    "# Build full model using helper function\n",
    "resnet_model = build_model(resnet_base, resnet_preprocess)\n",
    "\n",
    "# Train the model\n",
    "history_resnet = resnet_model.fit(\n",
    "    train_gen,                # training generator\n",
    "    validation_data=val_gen,  # validation generator\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57661e6c",
   "metadata": {},
   "source": [
    "### Train with VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d240b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 2s/step - accuracy: 0.1722 - loss: 3.1474 - val_accuracy: 0.1885 - val_loss: 1.8220\n",
      "Epoch 2/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 2s/step - accuracy: 0.1694 - loss: 2.3559 - val_accuracy: 0.1891 - val_loss: 1.7890\n",
      "Epoch 3/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 2s/step - accuracy: 0.1681 - loss: 2.0872 - val_accuracy: 0.1898 - val_loss: 1.7832\n",
      "Epoch 4/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 2s/step - accuracy: 0.1691 - loss: 1.9357 - val_accuracy: 0.2037 - val_loss: 1.7804\n",
      "Epoch 5/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 2s/step - accuracy: 0.1760 - loss: 1.8618 - val_accuracy: 0.1910 - val_loss: 1.7785\n",
      "Epoch 6/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 2s/step - accuracy: 0.1970 - loss: 1.7971 - val_accuracy: 0.2043 - val_loss: 1.7751\n",
      "Epoch 7/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 2s/step - accuracy: 0.1883 - loss: 1.7868 - val_accuracy: 0.1841 - val_loss: 1.7732\n",
      "Epoch 8/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 2s/step - accuracy: 0.1958 - loss: 1.7738 - val_accuracy: 0.1860 - val_loss: 1.7728\n",
      "Epoch 9/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 2s/step - accuracy: 0.2138 - loss: 1.7659 - val_accuracy: 0.1860 - val_loss: 1.7712\n",
      "Epoch 10/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 2s/step - accuracy: 0.2193 - loss: 1.7625 - val_accuracy: 0.2100 - val_loss: 1.7686\n",
      "Epoch 11/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 2s/step - accuracy: 0.2282 - loss: 1.7570 - val_accuracy: 0.2037 - val_loss: 1.7678\n",
      "Epoch 12/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 2s/step - accuracy: 0.2350 - loss: 1.7548 - val_accuracy: 0.2081 - val_loss: 1.7651\n",
      "Epoch 13/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 2s/step - accuracy: 0.2398 - loss: 1.7533 - val_accuracy: 0.2094 - val_loss: 1.7639\n",
      "Epoch 14/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 2s/step - accuracy: 0.2438 - loss: 1.7492 - val_accuracy: 0.2125 - val_loss: 1.7621\n",
      "Epoch 15/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 2s/step - accuracy: 0.2397 - loss: 1.7451 - val_accuracy: 0.2182 - val_loss: 1.7603\n",
      "Epoch 16/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 2s/step - accuracy: 0.2477 - loss: 1.7418 - val_accuracy: 0.2176 - val_loss: 1.7585\n",
      "Epoch 17/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 2s/step - accuracy: 0.2590 - loss: 1.7362 - val_accuracy: 0.2290 - val_loss: 1.7573\n",
      "Epoch 18/50\n",
      "\u001b[1m105/198\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 2s/step - accuracy: 0.2552 - loss: 1.7314"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping callback\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',       # monitor validation loss\n",
    "    patience=5,               # stop if no improvement for 5 epochs\n",
    "    restore_best_weights=True # keep best model weights\n",
    ")\n",
    "\n",
    "# Build VGG19 base model\n",
    "vgg_base = VGG19(\n",
    "    weights=\"imagenet\",       # use pretrained ImageNet weights\n",
    "    include_top=False,        # exclude the fully connected layer\n",
    "    input_shape=(128, 128, 3)\n",
    ")\n",
    "\n",
    "# Build full model using helper function\n",
    "vgg_model = build_model(vgg_base, vgg_preprocess)\n",
    "\n",
    "# Train the model\n",
    "history_vgg = vgg_model.fit(\n",
    "    train_gen,                # training generator\n",
    "    validation_data=val_gen,  # validation generator\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc3fefa",
   "metadata": {},
   "source": [
    "\n",
    "### Train with MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fe6f80c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 1s/step - accuracy: 0.1861 - loss: 1.8235 - val_accuracy: 0.2113 - val_loss: 1.7795\n",
      "Epoch 2/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 1s/step - accuracy: 0.2079 - loss: 1.7719 - val_accuracy: 0.1879 - val_loss: 1.7781\n",
      "Epoch 3/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 1s/step - accuracy: 0.2274 - loss: 1.7565 - val_accuracy: 0.2106 - val_loss: 1.7701\n",
      "Epoch 4/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 1s/step - accuracy: 0.2501 - loss: 1.7419 - val_accuracy: 0.2625 - val_loss: 1.7598\n",
      "Epoch 5/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 1s/step - accuracy: 0.2651 - loss: 1.7253 - val_accuracy: 0.2612 - val_loss: 1.7524\n",
      "Epoch 6/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 620ms/step - accuracy: 0.2749 - loss: 1.7119 - val_accuracy: 0.2663 - val_loss: 1.7455\n",
      "Epoch 7/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 421ms/step - accuracy: 0.2836 - loss: 1.6914 - val_accuracy: 0.2479 - val_loss: 1.7421\n",
      "Epoch 8/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 418ms/step - accuracy: 0.2871 - loss: 1.6755 - val_accuracy: 0.2846 - val_loss: 1.7353\n",
      "Epoch 9/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 435ms/step - accuracy: 0.2947 - loss: 1.6635 - val_accuracy: 0.2853 - val_loss: 1.7351\n",
      "Epoch 10/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 430ms/step - accuracy: 0.2991 - loss: 1.6494 - val_accuracy: 0.2555 - val_loss: 1.7260\n",
      "Epoch 11/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 483ms/step - accuracy: 0.2994 - loss: 1.6387 - val_accuracy: 0.2391 - val_loss: 1.7299\n",
      "Epoch 12/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 457ms/step - accuracy: 0.2959 - loss: 1.6275 - val_accuracy: 0.2726 - val_loss: 1.7198\n",
      "Epoch 13/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 384ms/step - accuracy: 0.3019 - loss: 1.6135 - val_accuracy: 0.2340 - val_loss: 1.7404\n",
      "Epoch 14/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 392ms/step - accuracy: 0.3113 - loss: 1.6069 - val_accuracy: 0.3011 - val_loss: 1.7184\n",
      "Epoch 15/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 388ms/step - accuracy: 0.3106 - loss: 1.5992 - val_accuracy: 0.2859 - val_loss: 1.7255\n",
      "Epoch 16/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 389ms/step - accuracy: 0.3116 - loss: 1.5916 - val_accuracy: 0.2815 - val_loss: 1.7145\n",
      "Epoch 17/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 400ms/step - accuracy: 0.3140 - loss: 1.5864 - val_accuracy: 0.2694 - val_loss: 1.7139\n",
      "Epoch 18/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 393ms/step - accuracy: 0.3184 - loss: 1.5795 - val_accuracy: 0.3093 - val_loss: 1.7125\n",
      "Epoch 19/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 406ms/step - accuracy: 0.3136 - loss: 1.5762 - val_accuracy: 0.2973 - val_loss: 1.7165\n",
      "Epoch 20/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 416ms/step - accuracy: 0.3141 - loss: 1.5755 - val_accuracy: 0.2657 - val_loss: 1.7243\n",
      "Epoch 21/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 411ms/step - accuracy: 0.3149 - loss: 1.5702 - val_accuracy: 0.2897 - val_loss: 1.7220\n",
      "Epoch 22/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 412ms/step - accuracy: 0.3198 - loss: 1.5664 - val_accuracy: 0.2783 - val_loss: 1.7211\n",
      "Epoch 23/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 394ms/step - accuracy: 0.3204 - loss: 1.5617 - val_accuracy: 0.2657 - val_loss: 1.7301\n"
     ]
    }
   ],
   "source": [
    "# Early stopping to prevent overfitting\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Build MobileNetV2 base model with new input size\n",
    "mobilenet_base = MobileNetV2(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)   # Updated from (128,128,3)\n",
    ")\n",
    "\n",
    "# Build complete model\n",
    "mobilenet_model = build_model(mobilenet_base, mobilenet_preprocess)\n",
    "\n",
    "# Train the model\n",
    "history_mobilenet = mobilenet_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23554b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf5ed32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['early_leaf_spot_1', 'early_rust_1', 'healthy_leaf_1', 'late_leaf_spot_1', 'nutrition_deficiency_1', 'rust_1']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = r\"E:\\A\\OneDrive\\Documents\\3rd year\\5th SEM Materials of SR.Mishra(3rd yr)\\Deep Learning for Image Analytics\\Project\\Groundnut_Leaf_dataset\\Main Used Dataset\"\n",
    "\n",
    "print(os.listdir(folder_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43596e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6329 images belonging to 6 classes.\n",
      "Found 1581 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_dir = r\"E:\\A\\OneDrive\\Documents\\3rd year\\5th SEM Materials of SR.Mishra(3rd yr)\\Deep Learning for Image Analytics\\Project\\Groundnut_Leaf_dataset\\Main Used Dataset\"\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13aa2f",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07519171",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\A\\\\OneDrive\\\\Documents\\\\3rd year\\\\5th SEM Materials of SR.Mishra(3rd yr)\\\\Deep Learning for Image Analytics\\\\Project\\\\Groundnut_Leaf_dataset\\\\Main Used Dataset\\\\retail_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m3rd year\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m5th SEM Materials of SR.Mishra(3rd yr)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDeep Learning for Image Analytics\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mProject\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mGroundnut_Leaf_dataset\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mMain Used Dataset\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mretail_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\A\\\\OneDrive\\\\Documents\\\\3rd year\\\\5th SEM Materials of SR.Mishra(3rd yr)\\\\Deep Learning for Image Analytics\\\\Project\\\\Groundnut_Leaf_dataset\\\\Main Used Dataset\\\\retail_data.csv'"
     ]
    }
   ],
   "source": [
    "# Evaluate all models on validation set\n",
    "resnet_acc = resnet_model.evaluate(val_gen, verbose=0)[1]\n",
    "vgg_acc = vgg_model.evaluate(val_gen, verbose=0)[1]\n",
    "mobilenet_acc = mobilenet_model.evaluate(val_gen, verbose=0)[1]\n",
    "\n",
    "print(f\"ResNet50 Accuracy: {resnet_acc:.4f}\")\n",
    "print(f\"VGG19 Accuracy: {vgg_acc:.4f}\")\n",
    "print(f\"MobileNetV2 Accuracy: {mobilenet_acc:.4f}\")\n",
    "\n",
    "# Automatically determine best model\n",
    "accuracies = {\n",
    "    \"ResNet50\": resnet_acc,\n",
    "    \"VGG19\": vgg_acc,\n",
    "    \"MobileNetV2\": mobilenet_acc\n",
    "}\n",
    "best_model_name = max(accuracies, key=accuracies.get)\n",
    "print(\"✅ Best Model:\", best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff14748",
   "metadata": {},
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# ResNet50\n",
    "plt.plot(history_resnet.history['accuracy'], '--', label=\"ResNet50 Train\")\n",
    "plt.plot(history_resnet.history['val_accuracy'], label=\"ResNet50 Val\")\n",
    "\n",
    "# VGG19\n",
    "plt.plot(history_vgg.history['accuracy'], '--', label=\"VGG19 Train\")\n",
    "plt.plot(history_vgg.history['val_accuracy'], label=\"VGG19 Val\")\n",
    "\n",
    "# MobileNetV2\n",
    "plt.plot(history_mobilenet.history['accuracy'], '--', label=\"MobileNetV2 Train\")\n",
    "plt.plot(history_mobilenet.history['val_accuracy'], label=\"MobileNetV2 Val\")\n",
    "\n",
    "plt.title(\"Training vs Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b156242d",
   "metadata": {},
   "source": [
    "### Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically save the best model\n",
    "if best_model_name == \"ResNet50\":\n",
    "    resnet_model.save(\"best_groundnut_model.h5\")\n",
    "elif best_model_name == \"VGG19\":\n",
    "    vgg_model.save(\"best_groundnut_model.h5\")\n",
    "else:\n",
    "    mobilenet_model.save(\"best_groundnut_model.h5\")\n",
    "\n",
    "print(\"✅ Best model saved as 'best_groundnut_model.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c19d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e5f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28177a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6329 images belonging to 6 classes.\n",
      "Found 1581 images belonging to 6 classes.\n",
      "\n",
      "==============================\n",
      "🚀 Training Model: MobileNetV2\n",
      "==============================\n",
      "\n",
      "🔍 Testing Params for MobileNetV2: {'batch_size': 16, 'dropout_rate': 0.3, 'lr': 0.0001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 1s/step - accuracy: 0.3263 - loss: 1.7001 - val_accuracy: 0.4788 - val_loss: 1.3648\n",
      "Epoch 2/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 871ms/step - accuracy: 0.5473 - loss: 1.1600 - val_accuracy: 0.6104 - val_loss: 1.0877\n",
      "Epoch 3/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 872ms/step - accuracy: 0.6514 - loss: 0.9433 - val_accuracy: 0.6597 - val_loss: 0.9650\n",
      "Epoch 4/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 872ms/step - accuracy: 0.6902 - loss: 0.8204 - val_accuracy: 0.6970 - val_loss: 0.8781\n",
      "Epoch 5/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 879ms/step - accuracy: 0.7365 - loss: 0.7337 - val_accuracy: 0.7204 - val_loss: 0.8211\n",
      "Epoch 6/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 876ms/step - accuracy: 0.7573 - loss: 0.6820 - val_accuracy: 0.7400 - val_loss: 0.7937\n",
      "Epoch 7/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 876ms/step - accuracy: 0.7744 - loss: 0.6304 - val_accuracy: 0.7634 - val_loss: 0.7360\n",
      "Epoch 8/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 873ms/step - accuracy: 0.7870 - loss: 0.5882 - val_accuracy: 0.7672 - val_loss: 0.7267\n",
      "Epoch 9/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 877ms/step - accuracy: 0.7940 - loss: 0.5782 - val_accuracy: 0.7691 - val_loss: 0.7126\n",
      "Epoch 10/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 874ms/step - accuracy: 0.8012 - loss: 0.5489 - val_accuracy: 0.7799 - val_loss: 0.6879\n",
      "\n",
      "🔍 Testing Params for MobileNetV2: {'batch_size': 16, 'dropout_rate': 0.3, 'lr': 0.0005}\n",
      "Epoch 1/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 888ms/step - accuracy: 0.5868 - loss: 1.0938 - val_accuracy: 0.7457 - val_loss: 0.7961\n",
      "Epoch 2/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 873ms/step - accuracy: 0.7788 - loss: 0.6154 - val_accuracy: 0.7938 - val_loss: 0.6657\n",
      "Epoch 3/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 872ms/step - accuracy: 0.8191 - loss: 0.5048 - val_accuracy: 0.8090 - val_loss: 0.6009\n",
      "Epoch 4/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 875ms/step - accuracy: 0.8368 - loss: 0.4452 - val_accuracy: 0.8020 - val_loss: 0.6287\n",
      "Epoch 5/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 882ms/step - accuracy: 0.8527 - loss: 0.4061 - val_accuracy: 0.8267 - val_loss: 0.5637\n",
      "Epoch 6/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 875ms/step - accuracy: 0.8603 - loss: 0.3869 - val_accuracy: 0.8381 - val_loss: 0.5454\n",
      "Epoch 7/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 881ms/step - accuracy: 0.8689 - loss: 0.3586 - val_accuracy: 0.8355 - val_loss: 0.5597\n",
      "Epoch 8/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 879ms/step - accuracy: 0.8783 - loss: 0.3425 - val_accuracy: 0.8349 - val_loss: 0.5324\n",
      "Epoch 9/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 877ms/step - accuracy: 0.8842 - loss: 0.3257 - val_accuracy: 0.8539 - val_loss: 0.5264\n",
      "Epoch 10/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 874ms/step - accuracy: 0.8836 - loss: 0.3193 - val_accuracy: 0.8526 - val_loss: 0.5290\n",
      "\n",
      "🔍 Testing Params for MobileNetV2: {'batch_size': 16, 'dropout_rate': 0.4, 'lr': 0.0001}\n",
      "Epoch 1/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 891ms/step - accuracy: 0.3361 - loss: 1.7465 - val_accuracy: 0.5376 - val_loss: 1.2564\n",
      "Epoch 2/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m773s\u001b[0m 4s/step - accuracy: 0.5222 - loss: 1.2342 - val_accuracy: 0.6350 - val_loss: 1.0365\n",
      "Epoch 3/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1678s\u001b[0m 9s/step - accuracy: 0.6221 - loss: 0.9998 - val_accuracy: 0.7103 - val_loss: 0.8876\n",
      "Epoch 4/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 879ms/step - accuracy: 0.6750 - loss: 0.8674 - val_accuracy: 0.7128 - val_loss: 0.8581\n",
      "Epoch 5/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 873ms/step - accuracy: 0.6992 - loss: 0.7962 - val_accuracy: 0.7343 - val_loss: 0.8031\n",
      "Epoch 6/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 873ms/step - accuracy: 0.7304 - loss: 0.7404 - val_accuracy: 0.7495 - val_loss: 0.7718\n",
      "Epoch 7/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 874ms/step - accuracy: 0.7467 - loss: 0.6902 - val_accuracy: 0.7546 - val_loss: 0.7429\n",
      "Epoch 8/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 873ms/step - accuracy: 0.7666 - loss: 0.6448 - val_accuracy: 0.7704 - val_loss: 0.7232\n",
      "Epoch 9/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 876ms/step - accuracy: 0.7783 - loss: 0.6198 - val_accuracy: 0.7641 - val_loss: 0.7128\n",
      "Epoch 10/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 871ms/step - accuracy: 0.7832 - loss: 0.5955 - val_accuracy: 0.7887 - val_loss: 0.6718\n",
      "\n",
      "🔍 Testing Params for MobileNetV2: {'batch_size': 16, 'dropout_rate': 0.4, 'lr': 0.0005}\n",
      "Epoch 1/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 892ms/step - accuracy: 0.5614 - loss: 1.1454 - val_accuracy: 0.7084 - val_loss: 0.8289\n",
      "Epoch 2/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 874ms/step - accuracy: 0.7527 - loss: 0.6604 - val_accuracy: 0.7875 - val_loss: 0.6746\n",
      "Epoch 3/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 875ms/step - accuracy: 0.8041 - loss: 0.5486 - val_accuracy: 0.8001 - val_loss: 0.6343\n",
      "Epoch 4/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 877ms/step - accuracy: 0.8226 - loss: 0.4920 - val_accuracy: 0.8052 - val_loss: 0.6099\n",
      "Epoch 5/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 878ms/step - accuracy: 0.8431 - loss: 0.4506 - val_accuracy: 0.8191 - val_loss: 0.5859\n",
      "Epoch 6/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 874ms/step - accuracy: 0.8466 - loss: 0.4119 - val_accuracy: 0.8153 - val_loss: 0.5804\n",
      "Epoch 7/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 877ms/step - accuracy: 0.8523 - loss: 0.3952 - val_accuracy: 0.8121 - val_loss: 0.5869\n",
      "Epoch 8/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 874ms/step - accuracy: 0.8580 - loss: 0.3811 - val_accuracy: 0.8355 - val_loss: 0.5710\n",
      "Epoch 9/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 876ms/step - accuracy: 0.8630 - loss: 0.3738 - val_accuracy: 0.8349 - val_loss: 0.5662\n",
      "Epoch 10/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 877ms/step - accuracy: 0.8719 - loss: 0.3556 - val_accuracy: 0.8248 - val_loss: 0.5802\n",
      "\n",
      "🔍 Testing Params for MobileNetV2: {'batch_size': 32, 'dropout_rate': 0.3, 'lr': 0.0001}\n",
      "Epoch 1/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 892ms/step - accuracy: 0.3143 - loss: 1.7538 - val_accuracy: 0.4965 - val_loss: 1.3341\n",
      "Epoch 2/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 883ms/step - accuracy: 0.5312 - loss: 1.1903 - val_accuracy: 0.6034 - val_loss: 1.0755\n",
      "Epoch 3/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 877ms/step - accuracy: 0.6369 - loss: 0.9433 - val_accuracy: 0.6686 - val_loss: 0.9379\n",
      "Epoch 4/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 881ms/step - accuracy: 0.6979 - loss: 0.8223 - val_accuracy: 0.7078 - val_loss: 0.8680\n",
      "Epoch 5/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 880ms/step - accuracy: 0.7268 - loss: 0.7457 - val_accuracy: 0.7255 - val_loss: 0.8111\n",
      "Epoch 6/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 877ms/step - accuracy: 0.7556 - loss: 0.6830 - val_accuracy: 0.7432 - val_loss: 0.7676\n",
      "Epoch 7/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 876ms/step - accuracy: 0.7752 - loss: 0.6262 - val_accuracy: 0.7521 - val_loss: 0.7579\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 882ms/step - accuracy: 0.7870 - loss: 0.5914 - val_accuracy: 0.7527 - val_loss: 0.7332\n",
      "Epoch 9/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 876ms/step - accuracy: 0.7925 - loss: 0.5748 - val_accuracy: 0.7672 - val_loss: 0.7081\n",
      "Epoch 10/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 881ms/step - accuracy: 0.8014 - loss: 0.5505 - val_accuracy: 0.7672 - val_loss: 0.6891\n",
      "\n",
      "🔍 Testing Params for MobileNetV2: {'batch_size': 32, 'dropout_rate': 0.3, 'lr': 0.0005}\n",
      "Epoch 1/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 887ms/step - accuracy: 0.5906 - loss: 1.0688 - val_accuracy: 0.7432 - val_loss: 0.8158\n",
      "Epoch 2/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 870ms/step - accuracy: 0.7748 - loss: 0.6189 - val_accuracy: 0.7862 - val_loss: 0.6808\n",
      "Epoch 3/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 868ms/step - accuracy: 0.8128 - loss: 0.5130 - val_accuracy: 0.8065 - val_loss: 0.6337\n",
      "Epoch 4/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 869ms/step - accuracy: 0.8368 - loss: 0.4555 - val_accuracy: 0.8216 - val_loss: 0.5854\n",
      "Epoch 5/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 855ms/step - accuracy: 0.8535 - loss: 0.4028 - val_accuracy: 0.8235 - val_loss: 0.6036\n",
      "Epoch 6/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 868ms/step - accuracy: 0.8589 - loss: 0.3943 - val_accuracy: 0.8216 - val_loss: 0.6038\n",
      "Epoch 7/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 868ms/step - accuracy: 0.8708 - loss: 0.3595 - val_accuracy: 0.8280 - val_loss: 0.5684\n",
      "Epoch 8/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 869ms/step - accuracy: 0.8763 - loss: 0.3442 - val_accuracy: 0.8400 - val_loss: 0.5469\n",
      "Epoch 9/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 869ms/step - accuracy: 0.8805 - loss: 0.3292 - val_accuracy: 0.8526 - val_loss: 0.5413\n",
      "Epoch 10/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4324s\u001b[0m 22s/step - accuracy: 0.8869 - loss: 0.3156 - val_accuracy: 0.8324 - val_loss: 0.5539\n",
      "\n",
      "🔍 Testing Params for MobileNetV2: {'batch_size': 32, 'dropout_rate': 0.4, 'lr': 0.0001}\n",
      "Epoch 1/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 891ms/step - accuracy: 0.3016 - loss: 1.8460 - val_accuracy: 0.5452 - val_loss: 1.2673\n",
      "Epoch 2/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 874ms/step - accuracy: 0.5149 - loss: 1.2381 - val_accuracy: 0.6464 - val_loss: 1.0207\n",
      "Epoch 3/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 874ms/step - accuracy: 0.6102 - loss: 1.0092 - val_accuracy: 0.6939 - val_loss: 0.9077\n",
      "Epoch 4/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 872ms/step - accuracy: 0.6718 - loss: 0.8873 - val_accuracy: 0.7236 - val_loss: 0.8398\n",
      "Epoch 5/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4620s\u001b[0m 23s/step - accuracy: 0.7025 - loss: 0.7959 - val_accuracy: 0.7274 - val_loss: 0.7999\n",
      "Epoch 6/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 876ms/step - accuracy: 0.7320 - loss: 0.7237 - val_accuracy: 0.7394 - val_loss: 0.7741\n",
      "Epoch 7/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 873ms/step - accuracy: 0.7480 - loss: 0.6911 - val_accuracy: 0.7590 - val_loss: 0.7462\n",
      "Epoch 8/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 873ms/step - accuracy: 0.7649 - loss: 0.6422 - val_accuracy: 0.7736 - val_loss: 0.7042\n",
      "Epoch 9/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 872ms/step - accuracy: 0.7731 - loss: 0.6176 - val_accuracy: 0.7843 - val_loss: 0.6844\n",
      "Epoch 10/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 872ms/step - accuracy: 0.7827 - loss: 0.5864 - val_accuracy: 0.7862 - val_loss: 0.6626\n",
      "\n",
      "🔍 Testing Params for MobileNetV2: {'batch_size': 32, 'dropout_rate': 0.4, 'lr': 0.0005}\n",
      "Epoch 1/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 885ms/step - accuracy: 0.5668 - loss: 1.1410 - val_accuracy: 0.7464 - val_loss: 0.8088\n",
      "Epoch 2/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 869ms/step - accuracy: 0.7535 - loss: 0.6679 - val_accuracy: 0.7786 - val_loss: 0.7106\n",
      "Epoch 3/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 869ms/step - accuracy: 0.7952 - loss: 0.5534 - val_accuracy: 0.7723 - val_loss: 0.6862\n",
      "Epoch 4/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 870ms/step - accuracy: 0.8134 - loss: 0.5001 - val_accuracy: 0.8039 - val_loss: 0.6287\n",
      "Epoch 5/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19659s\u001b[0m 100s/step - accuracy: 0.8376 - loss: 0.4423 - val_accuracy: 0.8229 - val_loss: 0.5835\n",
      "Epoch 6/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 875ms/step - accuracy: 0.8485 - loss: 0.4183 - val_accuracy: 0.8178 - val_loss: 0.5912\n",
      "Epoch 7/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 872ms/step - accuracy: 0.8524 - loss: 0.4042 - val_accuracy: 0.8159 - val_loss: 0.5905\n",
      "Epoch 8/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 871ms/step - accuracy: 0.8570 - loss: 0.3901 - val_accuracy: 0.8286 - val_loss: 0.5641\n",
      "Epoch 9/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 871ms/step - accuracy: 0.8592 - loss: 0.3730 - val_accuracy: 0.8343 - val_loss: 0.5519\n",
      "Epoch 10/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 871ms/step - accuracy: 0.8690 - loss: 0.3503 - val_accuracy: 0.8457 - val_loss: 0.5273\n",
      "\n",
      "✅ Best for MobileNetV2: {'batch_size': 16, 'dropout_rate': 0.3, 'lr': 0.0005} with Accuracy: 0.8539\n",
      "\n",
      "==============================\n",
      "🚀 Training Model: VGG19\n",
      "==============================\n",
      "\n",
      "🔍 Testing Params for VGG19: {'batch_size': 16, 'dropout_rate': 0.3, 'lr': 0.0001}\n",
      "Epoch 1/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2040s\u001b[0m 10s/step - accuracy: 0.1789 - loss: 1.9452 - val_accuracy: 0.2132 - val_loss: 1.7653\n",
      "Epoch 2/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4022s\u001b[0m 20s/step - accuracy: 0.2236 - loss: 1.8077 - val_accuracy: 0.3264 - val_loss: 1.7000\n",
      "Epoch 3/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8600s\u001b[0m 44s/step - accuracy: 0.2863 - loss: 1.7162 - val_accuracy: 0.3934 - val_loss: 1.6430\n",
      "Epoch 4/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7874s\u001b[0m 40s/step - accuracy: 0.3261 - loss: 1.6426 - val_accuracy: 0.4390 - val_loss: 1.5900\n",
      "Epoch 5/10\n",
      "\u001b[1m169/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m18:32\u001b[0m 38s/step - accuracy: 0.3546 - loss: 1.5888"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG19, ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# ===============================\n",
    "#  Dataset Path\n",
    "# ===============================\n",
    "dataset_path = r\"E:\\A\\OneDrive\\Documents\\3rd year\\5th SEM Materials of SR.Mishra(3rd yr)\\Deep Learning for Image Analytics\\Project\\Groundnut_Leaf_dataset\\Main Used Dataset\"\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# ===============================\n",
    "#  Data Preprocessing\n",
    "# ===============================\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "num_classes = len(train_gen.class_indices)\n",
    "\n",
    "# ===============================\n",
    "#  Model Builder Functions\n",
    "# ===============================\n",
    "\n",
    "def build_mobilenet_model(lr=1e-4, dropout_rate=0.3):\n",
    "    base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def build_vgg19_model(lr=1e-4, dropout_rate=0.3):\n",
    "    base_model = VGG19(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def build_resnet50_model(lr=1e-4, dropout_rate=0.3):\n",
    "    base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# ===============================\n",
    "#  Hyperparameter Grid\n",
    "# ===============================\n",
    "param_grid = {\n",
    "    'lr': [1e-4, 5e-4],\n",
    "    'dropout_rate': [0.3, 0.4],\n",
    "    'batch_size': [16, 32]\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "#  Model Comparison\n",
    "# ===============================\n",
    "model_builders = {\n",
    "    \"MobileNetV2\": build_mobilenet_model,\n",
    "    \"VGG19\": build_vgg19_model,\n",
    "    \"ResNet50\": build_resnet50_model\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, builder in model_builders.items():\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"🚀 Training Model: {model_name}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    best_acc = 0\n",
    "    best_params = {}\n",
    "    best_model = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        print(f\"\\n🔍 Testing Params for {model_name}: {params}\")\n",
    "        model = builder(lr=params['lr'], dropout_rate=params['dropout_rate'])\n",
    "\n",
    "        history = model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=10,\n",
    "            batch_size=params['batch_size'],\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        val_acc = max(history.history['val_accuracy'])\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "\n",
    "    results[model_name] = {\"accuracy\": best_acc, \"params\": best_params}\n",
    "    print(f\"\\n✅ Best for {model_name}: {best_params} with Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "# ===============================\n",
    "#  Compare and Print Final Results\n",
    "# ===============================\n",
    "print(\"\\n==============================\")\n",
    "print(\"🏆 Final Model Comparison Results\")\n",
    "print(\"==============================\")\n",
    "for name, info in results.items():\n",
    "    print(f\"{name}: {info['accuracy']*100:.2f}% (Best Params: {info['params']})\")\n",
    "\n",
    "best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "print(f\"\\n🎯 Best Performing Model: {best_model_name} with Accuracy = {results[best_model_name]['accuracy']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e6de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
